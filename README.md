# Web Scraping and Data Analysis Project

This project demonstrates how to scrape structured data from websites using Python and then analyze it for patterns and insights. The workflow includes data extraction, cleaning, and implementation of best practices for reliable scraping.

## Key Tasks

* **Web Scraping**: Built a Python script using BeautifulSoup and Requests to extract structured data from websites.
* **Data Organization**: Collected and organized raw data into a Pandas DataFrame for cleaning and further analysis.
* **Scalability & Reliability**: Implemented error handling and request delays to ensure stable, scalable scraping without overloading servers.

## Tech Stack

* Python
* BeautifulSoup4, Requests (for scraping)
* Pandas, NumPy (for data manipulation)

## How to Run

1. Clone the repository:

   ```bash
   git clone https://github.com/a-aggarwal7/Web_scraping.git
   cd Web_scraping
   ```
2. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```
3. Run the script:

   ```bash
   jupyter notebook Web_scrape.ipynb
   ```
4. Run the cells step by step to scrape data, clean it, and perform analysis.


## Results

The project successfully scraped and structured website data, next steps would be to apply this technique to dynamic websites instead of the static to get better grasp on things. 

